{"iteration": 1, "episodes": 8, "train/loss": 0.0, "reward/mean": -0.25, "eval/mean_reward": -0.32, "eval/win_rate": 0.34}
{"iteration": 1, "episodes": 4, "train/loss": 0.0, "reward/mean": -0.5, "eval/mean_reward": 0.0, "eval/win_rate": 0.5}
{"iteration": 2, "episodes": 4, "train/loss": 0.0, "reward/mean": -0.5, "eval/mean_reward": 0.0, "eval/win_rate": 0.5}
{"iteration": 3, "episodes": 4, "train/loss": 0.0, "reward/mean": 0.5, "eval/mean_reward": 0.0, "eval/win_rate": 0.5}
{"iteration": 1, "episodes": 8, "train/loss": 0.374999463558197, "reward/mean": -0.25, "eval/mean_reward": 0.0, "eval/win_rate": 0.5}
{"iteration": 2, "episodes": 8, "train/loss": 0.5999997854232788, "reward/mean": 0.5, "eval/mean_reward": -0.6, "eval/win_rate": 0.2}
{"iteration": 3, "episodes": 8, "train/loss": 0.29999983310699463, "reward/mean": -0.25, "eval/mean_reward": -0.4, "eval/win_rate": 0.3}
{"iteration": 1, "episodes": 8, "train/loss": 0.374999463558197, "reward/mean": -0.25, "eval/mean_reward": -0.22, "eval/win_rate": 0.39}
{"iteration": 2, "episodes": 8, "train/loss": 0.14999914169311523, "reward/mean": -0.75, "eval/mean_reward": -0.28, "eval/win_rate": 0.36}
{"iteration": 3, "episodes": 8, "train/loss": 0.37499791383743286, "reward/mean": -0.25, "eval/mean_reward": -0.18, "eval/win_rate": 0.41}
{"iteration": 4, "episodes": 8, "train/loss": 0.35555416345596313, "reward/mean": 0.0, "eval/mean_reward": -0.3, "eval/win_rate": 0.35}
{"iteration": 5, "episodes": 8, "train/loss": 0.12499989569187164, "reward/mean": -0.75, "eval/mean_reward": -0.32, "eval/win_rate": 0.34}
{"iteration": 6, "episodes": 8, "train/loss": 0.2222193032503128, "reward/mean": -0.5, "eval/mean_reward": -0.3, "eval/win_rate": 0.35}
{"iteration": 7, "episodes": 8, "train/loss": 0.7777775526046753, "reward/mean": 0.25, "eval/mean_reward": -0.2, "eval/win_rate": 0.4}
{"iteration": 8, "episodes": 8, "train/loss": 0.39999857544898987, "reward/mean": 0.0, "eval/mean_reward": -0.26, "eval/win_rate": 0.37}
{"iteration": 9, "episodes": 8, "train/loss": 0.4000000059604645, "reward/mean": -0.5, "eval/mean_reward": -0.22, "eval/win_rate": 0.39}
{"iteration": 10, "episodes": 8, "train/loss": 0.3999978303909302, "reward/mean": -0.25, "eval/mean_reward": -0.24, "eval/win_rate": 0.38}
{"iteration": 1, "episodes": 8, "train/loss": 0.18277132511138916, "reward/mean": -0.25, "eval/mean_reward": -0.22, "eval/win_rate": 0.39}
{"iteration": 2, "episodes": 8, "train/loss": 0.2775755226612091, "reward/mean": -0.5, "eval/mean_reward": -0.32, "eval/win_rate": 0.34}
{"iteration": 1, "episodes": 4, "train/loss": 0.0, "reward/mean": -0.5, "eval/mean_reward": -0.2, "eval/win_rate": 0.4}
{"iteration": 2, "episodes": 4, "train/loss": 0.0, "reward/mean": -1.0, "eval/mean_reward": 0.2, "eval/win_rate": 0.6}
{"iteration": 1, "episodes": 8, "train/loss": -0.1300441473722458, "reward/mean": -0.25, "eval/mean_reward": -0.2, "eval/win_rate": 0.4}
{"iteration": 1, "episodes": 5, "train/loss": 5.433863639831543, "train/policy_loss": 2.255589246749878, "train/value_loss": 6.356549263000488, "reward/mean": -0.6, "eval/mean_reward": -0.6, "eval/win_rate": 0.2}
{"iteration": 2, "episodes": 5, "train/loss": 2.822596549987793, "train/policy_loss": 1.3729697465896606, "train/value_loss": 2.8992533683776855, "reward/mean": 0.6, "eval/mean_reward": -0.6, "eval/win_rate": 0.2}
{"iteration": 3, "episodes": 5, "train/loss": 2.2899744510650635, "train/policy_loss": 1.1776039600372314, "train/value_loss": 2.224740982055664, "reward/mean": 0.2, "eval/mean_reward": -0.2, "eval/win_rate": 0.4}
{"iteration": 4, "episodes": 5, "train/loss": 1.8468804359436035, "train/policy_loss": 1.0074877738952637, "train/value_loss": 1.6787853240966797, "reward/mean": 0.2, "eval/mean_reward": 0.2, "eval/win_rate": 0.6}
